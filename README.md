# **BEES Data Engineering â€“ Breweries Case**

Este repositÃ³rio faz referÃªncia ao case da ABInbev/BEES para o teste de Data Engineer. Ele aborda o processamento de dados de cervejarias usando uma arquitetura baseada em contÃªineres.

## ğŸ“ DescriÃ§Ã£o do Projeto
Este projeto foi desenvolvido para demonstrar a capacidade de consumir, transformar e armazenar dados de uma API de cervejarias utilizando tecnologias modernas de Data Engineering. A orquestraÃ§Ã£o de tarefas foi realizada com Apache Airflow, e o processamento de dados foi feito usando Apache Spark. O Jupyter Notebook foi utilizado para visualizaÃ§Ã£o e anÃ¡lise dos dados transformados.

## ğŸ“‚ Estrutura do Projeto
O projeto segue uma arquitetura baseada em contÃªineres:
~~~
â”œâ”€â”€ dags
â”‚   â”œâ”€â”€ bronze_layer_dag.py       # DAG responsÃ¡vel pela ingestÃ£o de dados da API
â”‚   â”œâ”€â”€ silver_layer_dag.py       # DAG para transformar os dados da camada Bronze para a Silver
â”œâ”€â”€ data
â”‚   â””â”€â”€ bronze                    # Pasta para iniciar a hierarquia de pastas para salvar os arquivos brutos
â”‚       â””â”€â”€ YYYY                  # Hierarquia de Ano
â”‚       â””â”€â”€ MM                    # Hierarquia de MÃªs
â”‚       â””â”€â”€ DD                    # Hierarquia de Dia
â”‚           â””â”€â”€ Beweries.json     # Arquivo bruto salvo diariamente
â”‚   â””â”€â”€ silver                    # Pasta para salvar os dados em formato .parquet]
â”‚       â””â”€â”€ *.parquet             # Arquivos em parquet.parquet
â”‚   â””â”€â”€ ntb_gold                  # Pasta para salvar o notebook
â”‚       â””â”€â”€ ntb_gold.ipynb        # Notebook para anÃ¡lise e visualizaÃ§Ã£o dos dados
â”œâ”€â”€ docker-compose.yml            # Arquivo para orquestrar os serviÃ§os em contÃªineres
â”œâ”€â”€ Dockerfile                    # Arquivo Docker para configurar o ambiente Airflow + Spark
â””â”€â”€ README.md                     # DocumentaÃ§Ã£o do projeto
~~~

## ğŸ› ï¸ Tecnologias Utilizadas
- Docker: ContÃªinerizaÃ§Ã£o dos serviÃ§os e fÃ¡cil replicaÃ§Ã£o do ambiente.
- Apache Spark: Para processamento distribuÃ­do e transformaÃ§Ã£o dos dados.
- Apache Airflow: Para orquestraÃ§Ã£o e agendamento de tarefas.
- Jupyter Notebook: Para visualizaÃ§Ã£o e exploraÃ§Ã£o dos dados processados.
- Python: Linguagem principal utilizada no projeto.
- Pandas (opcional): Para manipulaÃ§Ã£o de dados no notebook.

## ğŸ¥‰ Camada Bronze
Os dados brutos sÃ£o salvos na camada Bronze em formato JSON, organizados em uma hierarquia de diretÃ³rios no seguinte formato:
~~~
YYYY/MM/DD/breweries.json
~~~
Essa organizaÃ§Ã£o facilita a consulta e o processamento incremental dos dados, permitindo a captura de dados diÃ¡rios de forma estruturada.

## ğŸ¥ˆ Camada Silver
Na camada Silver, os dados passam por um processamento para inclusÃ£o de colunas que acompanham o ciclo de vida das informaÃ§Ãµes. O processo Ã© o seguinte:

O pipeline verifica se jÃ¡ existem dados na camada Silver. Se nÃ£o houver dados:
- A camada Silver Ã© criada a partir dos dados da Bronze.
SÃ£o adicionadas duas colunas:
- insert_date: Preenchida com a data em que o dado foi inserido.
- update_date: Inicialmente nula, esta coluna sÃ³ serÃ¡ populada se o dado for atualizado no futuro.
Se jÃ¡ houver dados na camada Silver, o pipeline realiza um merge entre os dados novos e os antigos. Neste merge:
- A coluna insert_date mantÃ©m o valor original do dado.
- A coluna update_date Ã© atualizada com a data atual apenas se os dados tiverem sido modificados.

## ğŸ¥‡ Camada Gold
A camada Gold Ã© gerada a partir de um notebook que lÃª os dados processados na Silver, em formato Parquet, e realiza anÃ¡lises e visualizaÃ§Ãµes. O notebook utiliza a biblioteca Matplotlib para criar grÃ¡ficos que auxiliam na interpretaÃ§Ã£o dos dados, gerando insights a partir das informaÃ§Ãµes disponÃ­veis na camada Silver.

## ğŸš€ Como Executar o Projeto
Clone este repositÃ³rio:

~~~
git clone https://github.com/mateusccarvalho/ABInbev
~~~
Navegue atÃ© o diretÃ³rio do projeto:
~~~
cd ABInbev
~~~
Suba os contÃªineres com Docker Compose:
~~~
docker-compose up -d
~~~
Isso iniciarÃ¡ os serviÃ§os do Airflow, Spark e Jupyter Notebook.

Acesse o Apache Airflow em seu navegador para monitorar as DAGs:
~~~
http://localhost:8080
~~~
Credenciais padrÃ£o:

- UsuÃ¡rio: airflow
- Senha: airflow

Acesse o Jupyter Notebook:
~~~
http://localhost:8888/
~~~

## ğŸ“Š AnÃ¡lise dos Dados
Dentro do Jupyter Notebook, o arquivo ntb_gold.ipynb contÃ©m a anÃ¡lise e visualizaÃ§Ã£o dos dados. Ele demonstra:

- GrÃ¡fico mostrando o nÃºmero de cervejarias por estado e tipo.
  ![image](https://github.com/user-attachments/assets/5e9875b2-6b52-453a-89d7-318042d0b4c9)
- GrÃ¡fico mostrando o tipo de cervejaria
  ![image](https://github.com/user-attachments/assets/3a3fb7e0-554d-4ae2-a7f2-2975ea798521)
- GrÃ¡fico ilustrando a distribuiÃ§Ã£o das cervejarias por paÃ­s.
  ![image](https://github.com/user-attachments/assets/dd4df2a0-251c-47a9-acf8-1d1082fe108c)

## âš ï¸ Agradecimento
Este repositÃ³rio utilizou como base o seguinte projeto para desenvolvimento dos arquivos Docker:
https://github.com/airscholar/SparkingFlow
